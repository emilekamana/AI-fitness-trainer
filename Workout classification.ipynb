{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e802629-327a-4220-a97d-fba4e9135dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27e9ac-3ceb-4040-b1c5-ed62a159d8ec",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ad7f13-32b0-49d4-8976-873811cee443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/workout_model_2023-06-18 09:13:39.495369.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c631be-9fc2-44f1-86d8-ae82aae17df0",
   "metadata": {},
   "source": [
    "## visualize video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e07ded8-1405-414c-9308-84527bb8718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"videos/squat_11.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bf5e44-31f0-46b0-9861-ef6235f45c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 frames\n",
      "2.0 frames\n",
      "3.0 frames\n",
      "4.0 frames\n",
      "5.0 frames\n",
      "6.0 frames\n",
      "7.0 frames\n",
      "8.0 frames\n",
      "9.0 frames\n",
      "10.0 frames\n",
      "11.0 frames\n",
      "12.0 frames\n",
      "13.0 frames\n",
      "14.0 frames\n",
      "15.0 frames\n",
      "16.0 frames\n",
      "17.0 frames\n",
      "18.0 frames\n",
      "19.0 frames\n",
      "20.0 frames\n",
      "21.0 frames\n",
      "22.0 frames\n",
      "23.0 frames\n",
      "24.0 frames\n",
      "25.0 frames\n",
      "26.0 frames\n",
      "27.0 frames\n",
      "28.0 frames\n",
      "29.0 frames\n",
      "30.0 frames\n",
      "31.0 frames\n",
      "32.0 frames\n",
      "33.0 frames\n",
      "34.0 frames\n",
      "35.0 frames\n",
      "36.0 frames\n",
      "37.0 frames\n",
      "38.0 frames\n",
      "39.0 frames\n",
      "40.0 frames\n",
      "41.0 frames\n",
      "42.0 frames\n",
      "43.0 frames\n",
      "44.0 frames\n",
      "45.0 frames\n",
      "46.0 frames\n",
      "47.0 frames\n",
      "48.0 frames\n",
      "49.0 frames\n",
      "50.0 frames\n",
      "51.0 frames\n",
      "52.0 frames\n",
      "53.0 frames\n",
      "54.0 frames\n",
      "55.0 frames\n",
      "56.0 frames\n",
      "57.0 frames\n",
      "58.0 frames\n",
      "59.0 frames\n",
      "60.0 frames\n",
      "61.0 frames\n",
      "62.0 frames\n",
      "63.0 frames\n",
      "64.0 frames\n",
      "65.0 frames\n",
      "66.0 frames\n",
      "67.0 frames\n",
      "68.0 frames\n",
      "69.0 frames\n",
      "70.0 frames\n",
      "71.0 frames\n",
      "72.0 frames\n",
      "73.0 frames\n",
      "74.0 frames\n",
      "75.0 frames\n",
      "76.0 frames\n",
      "77.0 frames\n",
      "78.0 frames\n",
      "79.0 frames\n",
      "80.0 frames\n",
      "81.0 frames\n",
      "82.0 frames\n",
      "83.0 frames\n",
      "84.0 frames\n",
      "85.0 frames\n",
      "86.0 frames\n",
      "87.0 frames\n",
      "88.0 frames\n",
      "89.0 frames\n",
      "90.0 frames\n",
      "91.0 frames\n",
      "92.0 frames\n",
      "93.0 frames\n",
      "94.0 frames\n",
      "95.0 frames\n",
      "96.0 frames\n",
      "97.0 frames\n",
      "98.0 frames\n",
      "99.0 frames\n",
      "100.0 frames\n",
      "101.0 frames\n",
      "102.0 frames\n",
      "103.0 frames\n",
      "104.0 frames\n",
      "105.0 frames\n",
      "106.0 frames\n",
      "107.0 frames\n",
      "108.0 frames\n",
      "109.0 frames\n",
      "110.0 frames\n",
      "111.0 frames\n",
      "112.0 frames\n",
      "113.0 frames\n",
      "114.0 frames\n",
      "115.0 frames\n",
      "116.0 frames\n",
      "117.0 frames\n",
      "118.0 frames\n",
      "119.0 frames\n",
      "120.0 frames\n",
      "121.0 frames\n",
      "122.0 frames\n",
      "123.0 frames\n",
      "124.0 frames\n",
      "125.0 frames\n",
      "126.0 frames\n",
      "127.0 frames\n",
      "128.0 frames\n",
      "129.0 frames\n",
      "130.0 frames\n",
      "131.0 frames\n",
      "132.0 frames\n",
      "133.0 frames\n",
      "134.0 frames\n",
      "135.0 frames\n",
      "136.0 frames\n",
      "137.0 frames\n",
      "138.0 frames\n",
      "139.0 frames\n",
      "140.0 frames\n",
      "141.0 frames\n",
      "142.0 frames\n",
      "143.0 frames\n",
      "144.0 frames\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_file_name)\n",
    "while not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(video_file_name)\n",
    "    cv2.waitKey(1000)\n",
    "    print(\"Wait for the header\")\n",
    "\n",
    "pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "while True:\n",
    "    flag, frame = cap.read()\n",
    "    if flag:\n",
    "        # The frame is ready and already captured\n",
    "        cv2.imshow('video', frame)\n",
    "        pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        print(str(pos_frame)+\" frames\")\n",
    "    else:\n",
    "        # The next frame is not ready, so we try to read it again\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "        print(\"frame is not ready\")\n",
    "        # It is better to wait for a while for the next frame to be ready\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        # If the number of captured frames is equal to the total number of frames,\n",
    "        # we stop\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c149f706-f784-4276-95aa-86be59828e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows() # destroy all opened windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549f61e-1f1e-4ba9-b70d-ebf7c0967c38",
   "metadata": {},
   "source": [
    "## Evaluate classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae88ea1-b192-4ec4-89f3-a0300909912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "                                         tf.keras.layers.GaussianNoise(0.1),\n",
    "                                         tf.keras.layers.RandomContrast(0.1),\n",
    "                                         tf.keras.layers.RandomBrightness(0.1),\n",
    "                                         tf.keras.layers.RandomZoom(0.1)\n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e07499-c030-46a5-9c93-28b862836b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(video_file_name)\n",
    "# while not cap.isOpened():\n",
    "#     cap = cv2.VideoCapture(video_file_name)\n",
    "#     cv2.waitKey(1000)\n",
    "#     print(\"Wait for the header\")\n",
    "\n",
    "# pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "# while True:\n",
    "#     flag, frame = cap.read()\n",
    "#     if flag:\n",
    "#         # The frame is ready and already captured\n",
    "\n",
    "#         # cv2.putText(frame, 'Exercise: ', (15,12),\n",
    "#         #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "#         resized_img = cv2.resize(frame, (256, 256))\n",
    "#         # resized_img = np.expand_dims(resized_img, axis=0) \n",
    "#         augmented_img = data_augmentation(resized_img)\n",
    "#         resized_img = np.expand_dims(augmented_img, axis=0)\n",
    "#         result = model.predict(resized_img)\n",
    "#         result = np.argmax(result, axis=1)\n",
    "#         print(\"model result: \" + str(result))\n",
    "        \n",
    "#         cv2.imshow('video', frame)\n",
    "#         pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "#         print(str(pos_frame)+\" frames\")\n",
    "#     else:\n",
    "#         # The next frame is not ready, so we try to read it again\n",
    "#         cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "#         print(\"frame is not ready\")\n",
    "#         # It is better to wait for a while for the next frame to be ready\n",
    "#         cv2.waitKey(1000)\n",
    "\n",
    "#     if cv2.waitKey(10) == 27:\n",
    "#         break\n",
    "#     if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "#         # If the number of captured frames is equal to the total number of frames,\n",
    "#         # we stop\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66a561-295e-46ed-a2e2-3dd993cc456d",
   "metadata": {},
   "source": [
    "## Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c7a0da-b719-4796-b1e2-08d35ce33a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7843b8e3-4e99-4980-a0e8-d87e4bd95db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mmp_pose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoseLandmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mPoseLandmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntEnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"The 33 pose landmarks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mNOSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_EYE_INNER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_EYE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_EYE_OUTER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_EYE_INNER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_EYE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_EYE_OUTER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_EAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_EAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mMOUTH_LEFT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mMOUTH_RIGHT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_SHOULDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_SHOULDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_ELBOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_ELBOW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_WRIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_WRIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_PINKY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_PINKY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_THUMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_THUMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_HIP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_HIP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_KNEE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_KNEE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_ANKLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_ANKLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_HEEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_HEEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mLEFT_FOOT_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mRIGHT_FOOT_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/homebrew/lib/python3.11/site-packages/mediapipe/python/solutions/pose.py\n",
       "\u001b[0;31mType:\u001b[0m           EnumType\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a63a3-80fe-4c76-a0b9-886acc4433cd",
   "metadata": {},
   "source": [
    "## Camera offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b27971-7ca2-4145-b6c9-19dfb7ef8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734ae471-3908-479a-aec3-56fd6d62ed9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Connect to webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "#     # Loop through every frame until we close our webcam\n",
    "#     while cap.isOpened(): \n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "#         # convert image coloring from BGR to RGB\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         frame.flags.writeable = False\n",
    "    \n",
    "#         # Make pose estimations\n",
    "#         results = pose.process(frame)\n",
    "    \n",
    "#         # convert image coloring from RGB to BGR\n",
    "#         frame.flags.writeable = True\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "#             left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "\n",
    "#             right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "#             nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x,landmarks[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "\n",
    "#             offset_angle = calculate_angle(left_shoulder, nose, right_shoulder)\n",
    "\n",
    "#             # print(offset_angle)\n",
    "\n",
    "#             cv2.putText(frame, 'Offset angle ' + str(offset_angle), \n",
    "#                     (15,int(30*frame_height/480)),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "#             # # Visualize left shoulder angle\n",
    "#             # cv2.putText(frame, str(int(left_angle)),\n",
    "#             #             tuple(np.multiply(left_shoulder, [frame_width, frame_height]).astype(int)),\n",
    "#             #             cv2.FONT_HERSHEY_SIMPLEX, (0.5*frame_height/480), (0, 255, 0), 2, cv2.LINE_AA\n",
    "#             #                     )\n",
    "\n",
    "#             # # Visualize right shoulder angle\n",
    "#             # cv2.putText(frame, str(int(right_angle)),\n",
    "#             #             tuple(np.multiply(right_shoulder, [frame_width, frame_height]).astype(int)),\n",
    "#             #             cv2.FONT_HERSHEY_SIMPLEX, (0.5*frame_height/480), (0, 255, 0), 2, cv2.LINE_AA\n",
    "#             #                     )\n",
    "\n",
    "            \n",
    "#             # for key in joint_coordinates.keys():\n",
    "#             #     joint_coordinates[key] = [landmarks[mp_pose.PoseLandmark[key].value].x,landmarks[mp_pose.PoseLandmark[[key]].value].y]\n",
    "                \n",
    "    \n",
    "#                 # Visualize left elbow angle}\n",
    "#                 # cv2.putText(frame, str(int(left_angle)),\n",
    "#                 #             tuple(np.multiply(left_elbow, [frame_width, frame_height]).astype(int)),\n",
    "#                 #             cv2.FONT_HERSHEY_SIMPLEX, (0.5*frame_height/480), (0, 255, 0), 2, cv2.LINE_AA\n",
    "#                 #                     )\n",
    "            \n",
    "#         except:\n",
    "#             print(\"error\")\n",
    "    \n",
    "#         # Render detections\n",
    "#         mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "#                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                 )\n",
    "        \n",
    "#         # Show image \n",
    "#         cv2.imshow('Webcam', frame)\n",
    "        \n",
    "#         # Checks whether q has been hit and stops the loop\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "#             break\n",
    "\n",
    "# # Releases the webcam\n",
    "# cap.release()\n",
    "# # Closes the frame\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0211e6aa-a030-4488-af07-0552cef85c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Releases the webcam\n",
    "cap.release()\n",
    "# Closes the frame\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807d111-a670-4e24-bc77-139a4ec12f6c",
   "metadata": {},
   "source": [
    "## Get angles from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa33421-a1dc-4652-bf8c-245b47575e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_angles_file_path = \"./exercise_cv_details/rep_angles-Table 1.csv\"\n",
    "\n",
    "angle_data = pd.read_csv(rep_angles_file_path, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829f9958-6cc6-4928-81a4-77de4aa5cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>required_cv_joints</th>\n",
       "      <th>angle_joint_1</th>\n",
       "      <th>angle_joint_1_a</th>\n",
       "      <th>angle_joint_1_b</th>\n",
       "      <th>angle_joint_1_c</th>\n",
       "      <th>joint_1_stage_1</th>\n",
       "      <th>joint_1_stage_2</th>\n",
       "      <th>joint_1_stage_3</th>\n",
       "      <th>offset_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>barbell biceps curl</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>30&lt;x&lt;160</td>\n",
       "      <td>30&gt;x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bench press</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST,HIP</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>45&lt;x&lt;160</td>\n",
       "      <td>45&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>deadlift</td>\n",
       "      <td>SHOULDER,HIP,KNEE</td>\n",
       "      <td>HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>100&lt;x&lt;160</td>\n",
       "      <td>100&gt;x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>hammer curl</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>30&lt;x&lt;160</td>\n",
       "      <td>30&gt;x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>hip thrust</td>\n",
       "      <td>KNEE,HIP,SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>50&gt;x</td>\n",
       "      <td>50&lt;x&lt;160</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>incline bench press</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST,HIP</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>45&lt;x&lt;160</td>\n",
       "      <td>45&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>lateral raises</td>\n",
       "      <td>SHOULDER,WRIST,HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>20&gt;x</td>\n",
       "      <td>20&lt;x&lt;80</td>\n",
       "      <td>x&gt;80</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>leg raises</td>\n",
       "      <td>HIP,ANKLE,SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>ANKLE</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>80&lt;x&lt;160</td>\n",
       "      <td>80&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>pull up</td>\n",
       "      <td>WRIST,ELBOW,SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>30&lt;x&lt;160</td>\n",
       "      <td>30&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>push up</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST,HIP</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>45&lt;x&lt;160</td>\n",
       "      <td>45&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>romanian deadlift</td>\n",
       "      <td>SHOULDER,HIP,KNEE</td>\n",
       "      <td>HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>100&lt;x&lt;160</td>\n",
       "      <td>100&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>shoulder press</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST,HIP</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>20&gt;x</td>\n",
       "      <td>20&lt;x&lt;160</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>squat</td>\n",
       "      <td>HIP, KNEE,ANKLE</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>HIP</td>\n",
       "      <td>KNEE</td>\n",
       "      <td>ANKLE</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>50&lt;x&lt;160</td>\n",
       "      <td>50&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>t bar row</td>\n",
       "      <td>ELBOW,SHOULDER,HIP,WRIST</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>HIP</td>\n",
       "      <td>x&gt;80</td>\n",
       "      <td>0&gt;x&gt;80</td>\n",
       "      <td>0&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>tricep dips</td>\n",
       "      <td>SHOULDER,ELBOW,WRIST</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>SHOULDER</td>\n",
       "      <td>ELBOW</td>\n",
       "      <td>WRIST</td>\n",
       "      <td>x&gt;160</td>\n",
       "      <td>80&gt;x&gt;169</td>\n",
       "      <td>80&gt;x</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                label        required_cv_joints angle_joint_1  \\\n",
       "0       0  barbell biceps curl      SHOULDER,ELBOW,WRIST         ELBOW   \n",
       "1       1          bench press  SHOULDER,ELBOW,WRIST,HIP         ELBOW   \n",
       "2       3             deadlift         SHOULDER,HIP,KNEE           HIP   \n",
       "3       5          hammer curl      SHOULDER,ELBOW,WRIST         ELBOW   \n",
       "4       6           hip thrust         KNEE,HIP,SHOULDER           HIP   \n",
       "5       7  incline bench press  SHOULDER,ELBOW,WRIST,HIP         ELBOW   \n",
       "6       9       lateral raises        SHOULDER,WRIST,HIP      SHOULDER   \n",
       "7      11           leg raises        HIP,ANKLE,SHOULDER           HIP   \n",
       "8      13              pull up      WRIST,ELBOW,SHOULDER         ELBOW   \n",
       "9      14              push up  SHOULDER,ELBOW,WRIST,HIP         ELBOW   \n",
       "10     15    romanian deadlift         SHOULDER,HIP,KNEE           HIP   \n",
       "11     17       shoulder press  SHOULDER,ELBOW,WRIST,HIP      SHOULDER   \n",
       "12     18                squat           HIP, KNEE,ANKLE          KNEE   \n",
       "13     19            t bar row  ELBOW,SHOULDER,HIP,WRIST      SHOULDER   \n",
       "14     20          tricep dips      SHOULDER,ELBOW,WRIST         ELBOW   \n",
       "\n",
       "   angle_joint_1_a angle_joint_1_b angle_joint_1_c joint_1_stage_1  \\\n",
       "0         SHOULDER           ELBOW           WRIST           x>160   \n",
       "1         SHOULDER           ELBOW           WRIST           x>160   \n",
       "2         SHOULDER             HIP            KNEE           x>160   \n",
       "3         SHOULDER           ELBOW           WRIST           x>160   \n",
       "4         SHOULDER             HIP            KNEE            50>x   \n",
       "5         SHOULDER           ELBOW           WRIST           x>160   \n",
       "6            WRIST        SHOULDER             HIP            20>x   \n",
       "7         SHOULDER             HIP           ANKLE           x>160   \n",
       "8         SHOULDER           ELBOW           WRIST           x>160   \n",
       "9         SHOULDER           ELBOW           WRIST           x>160   \n",
       "10        SHOULDER             HIP            KNEE           x>160   \n",
       "11           ELBOW        SHOULDER             HIP            20>x   \n",
       "12             HIP            KNEE           ANKLE           x>160   \n",
       "13           ELBOW        SHOULDER             HIP            x>80   \n",
       "14        SHOULDER           ELBOW           WRIST           x>160   \n",
       "\n",
       "   joint_1_stage_2 joint_1_stage_3 offset_range  \n",
       "0         30<x<160            30>x          NaN  \n",
       "1         45<x<160            45>x          <30  \n",
       "2        100<x<160           100>x          NaN  \n",
       "3         30<x<160            30>x          NaN  \n",
       "4         50<x<160           x>160          <30  \n",
       "5         45<x<160            45>x          <30  \n",
       "6          20<x<80            x>80          >30  \n",
       "7         80<x<160            80>x          <30  \n",
       "8         30<x<160            30>x          <30  \n",
       "9         45<x<160            45>x          <30  \n",
       "10       100<x<160           100>x          <30  \n",
       "11        20<x<160           x>160          NaN  \n",
       "12        50<x<160            50>x          <30  \n",
       "13          0>x>80             0>x          <30  \n",
       "14        80>x>169            80>x          <30  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d4f8dc-dfb8-47dd-a7ba-e21eea2f92d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  5,  6,  7,  9, 11, 13, 14, 15, 17, 18, 19, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_data['index'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee52e932-0c53-4a83-82e4-6a4a2e6b7ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise = angle_data[angle_data['index']==0]\n",
    "exercise.offset_range.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fbd70-045a-4d83-ab60-c0abdf797df7",
   "metadata": {},
   "source": [
    "## Check offset requirement from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b6074c-dde1-4cc3-97dc-3087b9e3a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"videos/squat_18.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0bde32-2e95-437e-a0e1-4a5a08a1a576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(video_file_name)\n",
    "# while not cap.isOpened():\n",
    "#     cap = cv2.VideoCapture(video_file_name)\n",
    "#     cv2.waitKey(1000)\n",
    "#     print(\"Wait for the header\")\n",
    "\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "#     exercise_pred_list = []\n",
    "#     exercise = \"\"\n",
    "#     pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "#     while True:\n",
    "#         flag, frame = cap.read()\n",
    "#         frame_height, frame_width, _ = frame.shape\n",
    "#         if flag:\n",
    "#             # The frame is ready and already captured\n",
    "    \n",
    "            \n",
    "#             # ================================\n",
    "#             # Predict exercise being perfomed\n",
    "#             # ================================\n",
    "#             resized_img = cv2.resize(frame, (256, 256))\n",
    "#             augmented_img = data_augmentation(resized_img)\n",
    "#             resized_img = np.expand_dims(augmented_img, axis=0)\n",
    "#             exercise_pred = model.predict(resized_img)\n",
    "#             exercise_pred = np.argmax(exercise_pred, axis=1)\n",
    "\n",
    "    \n",
    "#             exercise_pred_list.append(int(exercise_pred))\n",
    "    \n",
    "#             if(len(exercise_pred_list) > 25):\n",
    "#                 exercise_pred_list.pop(0)\n",
    "    \n",
    "#             exercise_index = max(set(exercise_pred_list), key=exercise_pred_list.count)\n",
    "#             exercise = angle_data[angle_data['index']==exercise_index]\n",
    "#             exercise_label = exercise.label.item()\n",
    "            \n",
    "    \n",
    "#             cv2.putText(frame, 'Exercise prediction: ' + str(exercise_label), \n",
    "#                         (15,int(30*frame_height/480)),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "#             # ================================\n",
    "#             # if exercise is not supported\n",
    "#             # ================================\n",
    "#             is_supported = exercise_index in angle_data['index'].unique()\n",
    "    \n",
    "#             if not is_supported:\n",
    "#                 cv2.putText(frame, 'Exercise is not supported', \n",
    "#                             (15,int(50*frame_height/480)),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "#             # ================================\n",
    "#             # if exercise is supported\n",
    "#             # ================================\n",
    "#             else:\n",
    "    \n",
    "#                 # ================================\n",
    "#                 # Get mediapipe pose estimations\n",
    "#                 # ================================\n",
    "    \n",
    "#                 # convert image coloring from BGR to RGB\n",
    "#                 frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#                 frame.flags.writeable = False\n",
    "            \n",
    "#                 # Make pose estimations\n",
    "#                 pose_results = pose.process(frame)\n",
    "            \n",
    "#                 # convert image coloring from RGB to BGR\n",
    "#                 frame.flags.writeable = True\n",
    "#                 frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)   \n",
    "\n",
    "                \n",
    "#                 # ================================\n",
    "#                 # Calculate camera horizontal offset\n",
    "#                 # =================================\n",
    "\n",
    "#                 landmarks = pose_results.pose_landmarks.landmark\n",
    "\n",
    "#                 left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x * frame_width,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y * frame_height]\n",
    "    \n",
    "#                 right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * frame_width,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * frame_height]\n",
    "                \n",
    "#                 nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x * frame_width,landmarks[mp_pose.PoseLandmark.NOSE.value].y* frame_height]\n",
    "    \n",
    "#                 offset_angle = calculate_angle(left_shoulder, nose, right_shoulder)\n",
    "\n",
    "#                 # ================================\n",
    "#                 # Check if offset matches requirements\n",
    "#                 # =================================\n",
    "\n",
    "#                 exercise_offset_range = exercise.offset_range.item()\n",
    "\n",
    "#                 if pd.isna(exercise_offset_range):\n",
    "#                     cv2.putText(frame, 'No Offset limit: ' + str(offset_angle), \n",
    "#                             (15,int(50*frame_height/480)),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "                \n",
    "#                 else:\n",
    "                    \n",
    "#                     # ================================\n",
    "#                     # if offset is outside recommended range\n",
    "#                     # =================================\n",
    "#                     if not eval(str(offset_angle)+str(exercise_offset_range)):\n",
    "#                         cv2.putText(frame, 'Failed Offset: ' + str(offset_angle), \n",
    "#                                 (15,int(50*frame_height/480)),\n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    \n",
    "#                     # ================================\n",
    "#                     # if offset is inside recommended range\n",
    "#                     # =================================\n",
    "#                     else:\n",
    "#                         cv2.putText(frame, 'Passed Offset: ' + str(offset_angle), \n",
    "#                                 (15,int(50*frame_height/480)),\n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "                \n",
    "#             cv2.imshow('video', frame)\n",
    "#             pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "#             print(str(pos_frame)+\" frames\")\n",
    "#         else:\n",
    "#             # The next frame is not ready, so we try to read it again\n",
    "#             cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "#             print(\"frame is not ready\")\n",
    "#             # It is better to wait for a while for the next frame to be ready\n",
    "#             cv2.waitKey(1000)\n",
    "    \n",
    "#         if cv2.waitKey(10) == 27:\n",
    "#             break\n",
    "#         if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "#             # If the number of captured frames is equal to the total number of frames,\n",
    "#             # we stop\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d11e6-49ef-4285-a310-7a1a2ebfa4cb",
   "metadata": {},
   "source": [
    "## Calculating reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2418df44-793b-4e9c-a7fb-8b7fd4ad48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = \"videos/leg raises_12.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cd76e06-ba6f-47df-bb17-23ca2757587c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "1.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713037044.661199       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "/var/folders/rz/9j2hj9093ksbzjby35l79ys80000gn/T/ipykernel_26349/3841751741.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  exercise_pred_list.append(int(exercise_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "3.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "4.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "5.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "6.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "7.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "8.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "9.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "10.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "11.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "12.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "13.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "14.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "15.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "16.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "17.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "18.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "19.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "20.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "21.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "22.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "23.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "24.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "25.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "26.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "27.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "28.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "29.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "30.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "31.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "32.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "33.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "34.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "35.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "36.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "37.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "38.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "39.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "40.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "41.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "42.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "43.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "44.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "45.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "46.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "47.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "48.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "49.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "50.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "51.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "52.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "53.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "54.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "55.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "56.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "57.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "58.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "59.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "60.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "61.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "62.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "63.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "64.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "65.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "66.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "67.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "68.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "69.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "70.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "71.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "72.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "73.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "74.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "75.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "76.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "77.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "78.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "79.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "80.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "81.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "82.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "83.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "84.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "85.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "86.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "87.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "88.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "89.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "90.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "91.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "92.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "93.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "94.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "95.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "96.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "97.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "98.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "99.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "100.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "101.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "102.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "103.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "104.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "105.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "106.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "107.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "108.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "109.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "110.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "111.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "112.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "113.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "114.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "115.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "116.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "117.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "118.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "119.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "120.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "121.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "122.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "123.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "124.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "125.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "126.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "127.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "128.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "129.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "130.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "131.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "132.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "133.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "134.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "135.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "136.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "137.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "138.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "139.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "140.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "141.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "142.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "143.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "144.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "145.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "146.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "147.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "148.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "149.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "150.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "151.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "152.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "153.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "154.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "155.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "156.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "157.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "158.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "159.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "160.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "161.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "162.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "163.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "164.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "165.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "166.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "167.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "168.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "169.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "170.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "171.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "172.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "173.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "174.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "175.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "176.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "177.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "178.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "179.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "180.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "181.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "182.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "183.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "184.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "185.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "186.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "187.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "188.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "189.0 frames\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "190.0 frames\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_file_name)\n",
    "while not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(video_file_name)\n",
    "    cv2.waitKey(1000)\n",
    "    print(\"Wait for the header\")\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    exercise_pred_list = []\n",
    "    exercise = \"\"\n",
    "    pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    stage_seq = []\n",
    "    stage = \"\"\n",
    "    correct_exercise_reps = {}\n",
    "    incorrect_exercise_reps = {}\n",
    "    while True:\n",
    "        flag, frame = cap.read()\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        if flag:\n",
    "            # The frame is ready and already captured\n",
    "    \n",
    "            \n",
    "            # ================================\n",
    "            # Predict exercise being perfomed\n",
    "            # ================================\n",
    "            resized_img = cv2.resize(frame, (256, 256))\n",
    "            augmented_img = data_augmentation(resized_img)\n",
    "            resized_img = np.expand_dims(augmented_img, axis=0)\n",
    "            exercise_pred = model.predict(resized_img)\n",
    "            exercise_pred = np.argmax(exercise_pred, axis=1)\n",
    "\n",
    "    \n",
    "            exercise_pred_list.append(int(exercise_pred))\n",
    "    \n",
    "            if(len(exercise_pred_list) > 25):\n",
    "                exercise_pred_list.pop(0)\n",
    "    \n",
    "            exercise_index = max(set(exercise_pred_list), key=exercise_pred_list.count)\n",
    "            exercise = angle_data[angle_data['index']==exercise_index]\n",
    "            exercise_label = str(exercise.label.item())\n",
    "\n",
    "            if exercise_label not in correct_exercise_reps:\n",
    "                correct_exercise_reps[exercise_label] = 0\n",
    "            if exercise_label not in incorrect_exercise_reps:\n",
    "                incorrect_exercise_reps[exercise_label] = 0\n",
    "            \n",
    "    \n",
    "            cv2.putText(frame, 'Exercise prediction: ' + str(exercise_label), \n",
    "                        (15,int(30*frame_height/480)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "            # ================================\n",
    "            # if exercise is not supported\n",
    "            # ================================\n",
    "            is_supported = exercise_index in angle_data['index'].unique()\n",
    "    \n",
    "            if not is_supported:\n",
    "                cv2.putText(frame, 'Exercise is not supported', \n",
    "                            (15,int(50*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "            # ================================\n",
    "            # if exercise is supported\n",
    "            # ================================\n",
    "            else:\n",
    "    \n",
    "                # ================================\n",
    "                # Get mediapipe pose estimations\n",
    "                # ================================\n",
    "    \n",
    "                # convert image coloring from BGR to RGB\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame.flags.writeable = False\n",
    "            \n",
    "                # Make pose estimations\n",
    "                pose_results = pose.process(frame)\n",
    "            \n",
    "                # convert image coloring from RGB to BGR\n",
    "                frame.flags.writeable = True\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)   \n",
    "\n",
    "                \n",
    "                # ================================\n",
    "                # Calculate camera horizontal offset\n",
    "                # =================================\n",
    "\n",
    "                landmarks = pose_results.pose_landmarks.landmark\n",
    "\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x * frame_width,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y * frame_height]\n",
    "    \n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x * frame_width,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y * frame_height]\n",
    "                \n",
    "                nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].x * frame_width,landmarks[mp_pose.PoseLandmark.NOSE.value].y* frame_height]\n",
    "    \n",
    "                offset_angle = calculate_angle(left_shoulder, nose, right_shoulder)\n",
    "\n",
    "                # ================================\n",
    "                # Check if offset matches requirements\n",
    "                # =================================\n",
    "\n",
    "                exercise_offset_range = exercise.offset_range.item()\n",
    "\n",
    "                if not pd.isna(exercise_offset_range) and not eval(str(offset_angle)+str(exercise_offset_range)):\n",
    "                    \n",
    "                    # ================================\n",
    "                    # if offset is outside recommended range\n",
    "                    # =================================\n",
    "                    cv2.putText(frame, 'Failed Offset: ' + str(offset_angle), \n",
    "                            (15,int(50*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    \n",
    "                # ================================\n",
    "                # if offset is inside recommended range\n",
    "                # =================================\n",
    "                else:\n",
    "                    cv2.putText(frame, 'Passed Offset: ' + str(offset_angle), \n",
    "                            (15,int(50*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    exercise_required_joints = exercise.required_cv_joints.item()\n",
    "\n",
    "                    all_joints = exercise_required_joints.split(',')\n",
    "                    \n",
    "                    left_joint = landmarks[mp_pose.PoseLandmark['LEFT_' + str(all_joints[0])]]\n",
    "                    right_joint = landmarks[mp_pose.PoseLandmark['RIGHT_' + str(all_joints[0])]]\n",
    "\n",
    "                    if left_joint.visibility > right_joint.visibility:\n",
    "\n",
    "                        cv2.putText(frame, str(all_joints[0]) + ' left: ' + str(left_joint.visibility), \n",
    "                            (15,int(70*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        rep_joint_a = [landmarks[mp_pose.PoseLandmark[f'LEFT_{str(exercise.angle_joint_1_a.item())}'].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"LEFT_{str(exercise.angle_joint_1_a.item())}\"].value].y * frame_height]\n",
    "                        rep_joint_b = [landmarks[mp_pose.PoseLandmark[f\"LEFT_{str(exercise.angle_joint_1_b.item())}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"LEFT_{str(exercise.angle_joint_1_b.item())}\"].value].y * frame_height]\n",
    "                        rep_joint_c = [landmarks[mp_pose.PoseLandmark[f\"LEFT_{str(exercise.angle_joint_1_c.item())}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"LEFT_{str(exercise.angle_joint_1_c.item())}\"].value].y * frame_height]\n",
    "\n",
    "                        joint_positions = { f\"LEFT_{joint}\":[landmarks[mp_pose.PoseLandmark[f\"LEFT_{joint}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"LEFT_{joint}\"].value].y * frame_height] for joint in all_joints }\n",
    "                        \n",
    "                    else:\n",
    "                        cv2.putText(frame, str(all_joints[0]) + ' right: ' + str(right_joint.visibility), \n",
    "                            (15,int(70*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "                        rep_joint_a = [landmarks[mp_pose.PoseLandmark[f'RIGHT_{str(exercise.angle_joint_1_a.item())}'].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"RIGHT_{str(exercise.angle_joint_1_a.item())}\"].value].y * frame_height]\n",
    "                        rep_joint_b = [landmarks[mp_pose.PoseLandmark[f\"RIGHT_{str(exercise.angle_joint_1_b.item())}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"RIGHT_{str(exercise.angle_joint_1_b.item())}\"].value].y * frame_height]\n",
    "                        rep_joint_c = [landmarks[mp_pose.PoseLandmark[f\"RIGHT_{str(exercise.angle_joint_1_c.item())}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"RIGHT_{str(exercise.angle_joint_1_c.item())}\"].value].y * frame_height]\n",
    "\n",
    "                        joint_positions = { f\"RIGHT_{joint}\":[landmarks[mp_pose.PoseLandmark[f\"RIGHT_{joint}\"].value].x * frame_width,landmarks[mp_pose.PoseLandmark[f\"RIGHT_{joint}\"].value].y * frame_height] for joint in all_joints }\n",
    "\n",
    "                    \n",
    "                    rep_angle = calculate_angle(rep_joint_a, rep_joint_b, rep_joint_c)\n",
    "\n",
    "                    \n",
    "                   \n",
    "                    # ================================\n",
    "                    # Get current exercise rep state\n",
    "                    # =================================\n",
    "                    stage_1_condition = str(exercise.joint_1_stage_1.item())\n",
    "                    stage_2_condition = str(exercise.joint_1_stage_2.item())\n",
    "                    stage_3_condition = str(exercise.joint_1_stage_3.item())\n",
    "\n",
    "                    if eval(stage_1_condition.replace('x', str(rep_angle))):\n",
    "                        stage = \"s1\"\n",
    "                    elif eval(stage_2_condition.replace('x', str(rep_angle))):\n",
    "                        stage = \"s2\"\n",
    "                    elif eval(stage_3_condition.replace('x', str(rep_angle))):\n",
    "                        stage = \"s3\"\n",
    "\n",
    "                    if stage == 's1':\n",
    "\n",
    "                        if len(stage_seq) == 3:\n",
    "                            correct_exercise_reps[exercise_label]+=1\n",
    "                            print(str(correct_exercise_reps[exercise_label]))\n",
    "                            \n",
    "                        elif 's2' in stage_seq and len(stage_seq)==1:\n",
    "                            incorrect_exercise_reps[exercise_label]+=1\n",
    "                            str(incorrect_exercise_reps[exercise_label])\n",
    "\n",
    "                        stage_seq = []\n",
    "                    \n",
    "                    elif stage == 's2':\n",
    "                        if (('s3' not in stage_seq) and (stage_seq.count('s2'))==0) or \\\n",
    "                            (('s3' in stage_seq) and (stage_seq.count('s2')==1)):\n",
    "                            stage_seq.append(stage)\n",
    "                            \n",
    "                    elif stage == 's3':\n",
    "                        if (stage not in stage_seq) and 's2' in stage_seq: \n",
    "                            stage_seq.append(stage)\n",
    "                            \n",
    "                    cv2.putText(frame, str(exercise_label) + ' correct reps: ' + str(correct_exercise_reps[exercise_label]), \n",
    "                            (15,int(90*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "            \n",
    "                    cv2.putText(frame, str(exercise_label) + ' incorrect reps: ' + str(incorrect_exercise_reps[exercise_label]), \n",
    "                            (15,int(110*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "                    cv2.putText(frame, 'stage: ' + str(stage), \n",
    "                            (15,int(130*frame_height/480)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    cv2.putText(frame, 'joint angle: ' + str(rep_angle), \n",
    "                                    (15,int(150*frame_height/480)),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "            cv2.imshow('video', frame)\n",
    "            pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            print(str(pos_frame)+\" frames\")\n",
    "        else:\n",
    "            # The next frame is not ready, so we try to read it again\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "            print(\"frame is not ready\")\n",
    "            # It is better to wait for a while for the next frame to be ready\n",
    "            cv2.waitKey(1000)\n",
    "    \n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            # If the number of captured frames is equal to the total number of frames,\n",
    "            # we stop\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e67717-fb98-4413-a68d-f98a63e23d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## straight body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee4fcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculate_distance(a,b):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Second\n",
    "    return math.sqrt((b[0] - a[0]) ** 2 + (b[1] - a[1]) ** 2 + (b[2] - a[2]) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed11a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713199251.639646       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# Connect to webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    max_back_length = 0\n",
    "    # Loop through every frame until we close our webcam\n",
    "    while cap.isOpened(): \n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "        # convert image coloring from BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame.flags.writeable = False\n",
    "    \n",
    "        # Make pose estimations\n",
    "        results = pose.process(frame)\n",
    "    \n",
    "        # convert image coloring from RGB to BGR\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "\n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            \n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            left_new_distance = calculate_angle(left_shoulder, left_hip, np.array([left_hip[0], 0]))\n",
    "            right_new_distance = calculate_angle(right_shoulder, right_hip, np.array([right_hip[0], 0]))\n",
    "            \n",
    "            \n",
    "            cv2.putText(frame, 'Angle left: ' + str(left_new_distance), \n",
    "                    (15,int(30*frame_height/480)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(frame, 'Angle right: ' + str(right_new_distance), \n",
    "                    (15,int(50*frame_height/480)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7*frame_height/480, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(\"error\")\n",
    "    \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                )\n",
    "                                \n",
    "        \n",
    "        # Show image \n",
    "        cv2.imshow('Webcam', frame)\n",
    "        \n",
    "        # Checks whether q has been hit and stops the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "# Releases the webcam\n",
    "cap.release()\n",
    "# Closes the frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f7fc2-64b3-49be-b4db-1ec26e378224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
